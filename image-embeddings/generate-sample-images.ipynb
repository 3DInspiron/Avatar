{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Images with Stable Diffusion\n",
    "Use this notebook to create images of various scenes for any subject you prefer. We use Azure OpenAI to create scene descriptions based on your subject.\n",
    "\n",
    "Example subject: __\"animal\"__ leads to scene discriptions like the following:  \n",
    "   \n",
    "\"Full shot raw photo of a majestic white tiger lounging on a rock ledge in a lush green forest setting\"  \n",
    "\"Wide angle photo of a playful group of dolphins leaping in the ocean waves with a sunlit horizon\"  \n",
    "\"Wide shot raw photo of a flock of birds taking flight over a serene beach during sunrise\"  \n",
    "...\n",
    "\n",
    "We are using these scene descriptions as input for text prompts to generate images with Stable Diffusion and Realistic Vision models. This way, you can easily generate hndreds of images of specific subject clusters (e.g., \"animal\", \"man\", \"woman\") as input for the image search demo scenarios of this repository.\n",
    "\n",
    "Use the `image_classes` dictionary below to specify, the subject classes, number of images, model and other parameters based on your preferences."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from diffusers import StableDiffusionPipeline, AutoencoderKL, DPMSolverMultistepScheduler\n",
    "import torch\n",
    "from IPython.display import display\n",
    "\n",
    "from utils import show_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv(\"AOAI_ENDPOINT\")\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "openai.api_key = os.getenv(\"AOAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(subject):\n",
    "\n",
    "    \"\"\"Generate a photo scene description based on a subject\"\"\"\n",
    "\n",
    "    messages = [{\"role\":\"system\",\"content\":\"You create a concise text prompt of one to two sentences to describe a scene of a photography based on a subject that the user provides. Be very creative and very diverse in selecting examples. Expand the given examples to add more aspects to the scene. \"},{\"role\":\"user\",\"content\":\"man\"},{\"role\":\"assistant\",\"content\":\"Medium shot raw photo of middle aged casually dressed English male tourist eating in a restaurant\"},{\"role\":\"user\",\"content\":\"man\"},{\"role\":\"assistant\",\"content\":\"Close up raw photo of young business formally dressed Asian businessman in a business meeting\"},{\"role\":\"user\",\"content\":\"woman\"},{\"role\":\"assistant\",\"content\":\"Medium shot raw photo of senior casually dressed African woman bicycling\"},{\"role\":\"user\",\"content\":\"woman\"},{\"role\":\"assistant\",\"content\":\"Full shot raw photo of young casually dressed German female tourist driving a a convertible\"},{\"role\":\"user\",\"content\":\"animal\"},{\"role\":\"assistant\",\"content\":\"Medium shot photo of a herd of elephants marching through the savannah with sunset in the background\"},{\"role\":\"user\",\"content\":\"animal\"},{\"role\":\"assistant\",\"content\":\"Closeup raw photo of a butterfly fluttering in a blooming garden with lake in the background\"}]\n",
    "    messages.append({\"role\":\"user\",\"content\": subject})                            \n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "    engine=\"gpt-4\",\n",
    "    messages = messages,\n",
    "    temperature=2.0,\n",
    "    max_tokens=800,\n",
    "    top_p=0.95,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    stop=None)\n",
    "\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "def generate_images(pipe, prompt, suffix, negative_prompt, num_images=1):\n",
    "\n",
    "    \"\"\"Generate images based on Diffusers pipeline, scene prompt, suffic, and negative prompt\"\"\"\n",
    "  \n",
    "    images = pipe(prompt=prompt + suffix,\n",
    "                negative_prompt=negative_prompt,\n",
    "                height=512,\n",
    "                width=768,\n",
    "                guidance_scale=7.5,\n",
    "                num_inference_steps=100,\n",
    "                num_images_per_prompt=num_images,\n",
    "                ).images\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Stable Diffusion Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StableDiffusionLongPromptWeightingPipeline {\n",
       "  \"_class_name\": \"StableDiffusionLongPromptWeightingPipeline\",\n",
       "  \"_diffusers_version\": \"0.16.1\",\n",
       "  \"feature_extractor\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPImageProcessor\"\n",
       "  ],\n",
       "  \"requires_safety_checker\": false,\n",
       "  \"safety_checker\": [\n",
       "    null,\n",
       "    null\n",
       "  ],\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"DPMSolverMultistepScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModel\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"unet\": [\n",
       "    \"diffusers\",\n",
       "    \"UNet2DConditionModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKL\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realistic Vision 2.0 for images of people\n",
    "rv20_pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"SG161222/Realistic_Vision_V2.0\",\n",
    "    # custom_pipeline= 'lpw_stable_diffusion',\n",
    "    torch_dtype=torch.float16,\n",
    "    ).to('cuda')\n",
    "\n",
    "# Stable Diffusion 2.1 for images of other subjects (e.g., animals)\n",
    "sd21_pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-2-1\",\n",
    "    custom_pipeline= 'lpw_stable_diffusion',\n",
    "    torch_dtype= torch.float16,\n",
    "    )\n",
    "\n",
    "sd21_pipe.scheduler = DPMSolverMultistepScheduler.from_config(sd21_pipe.scheduler.config)\n",
    "sd21_pipe.to('cuda')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify classes based on desired subjects\n",
    "Specify your desired image clusters (e.g., \"man\", \"woman\", \"children\"), the text2image vision model, number of samples, suffix to add to the scene description, and the negative prompt.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './testimages' # root folder for generated images\n",
    "\n",
    "rv20_suffix = \", (high detailed skin:1.2), 8k uhd, dslr, high quality, film grain, real-world, unedited, photorealistic, Fujifilm XT3, natural, authentic\"\n",
    "rv20_negative_prompt = '(semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime:1.4), text, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck'\n",
    "\n",
    "sd21_suffix = \", National Geographic Wildlife photo of the year, dslr, 8K UHD\"\n",
    "sd21_negative_prompt = 'deformed, disfigured, underexposed, overexposed'\n",
    "\n",
    "image_classes = [\n",
    "    {'classname': 'man', 'pipe' : rv20_pipe, 'samples' : 3, 'suffix' : rv20_suffix, 'negative_prompt' : rv20_negative_prompt },\n",
    "    {'classname': 'woman', 'pipe' : rv20_pipe, 'samples' : 3, 'suffix' : rv20_suffix, 'negative_prompt' : rv20_negative_prompt },\n",
    "    {'classname': 'children', 'pipe' : rv20_pipe, 'samples' : 3, 'suffix' : rv20_suffix, 'negative_prompt' : rv20_negative_prompt },\n",
    "    {'classname': 'animal', 'pipe' : sd21_pipe, 'samples' : 3, 'suffix' : sd21_suffix, 'negative_prompt' : sd21_negative_prompt },\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aerial shot raw photo of male urban hiphop street dancer performing in an outdoor event\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea4c895fa814f668a26f0b3a81fafef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full shot candid photo of a Latin-American street musician performing acoustic guitar in the midst of a bustling marketplace.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c1473617584a56bd09e0b19b2de10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wide shot raw photo of a professional Hispanic skateboarder performing a stunt in an urban skate park.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea7b96281e194e74989993cb78a8b21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wide shot photo of a latin American professional female dancer rehearsing gracefully in a rustic studio\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08916a1dbc764581a22fbde748f1bc6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aerial view raw photo of a Latina woman hiking on a narrow mountain trail, surrounded by lush forest foliage.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaea131e85c64dffadcc55d1f325fed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close-up photo of Latin female scientist examining chemical substances in a brightly lit laboratory\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "186d49b9402c4142829af47f80ee23ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium shot photo of a group of diverse children happily running on a vibrant playground in the park\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d046a9573b4eb38e1a6d98f14556ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full shot candid photo of a group of ethnically diverse children laughing and playing tag in a park\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d28a2ccccf64ae9a4bf08b74bebb96b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full shot raw photo of a diverse group of children joyfully playing in a colorful park with water splashing in a nearby fountain\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba7c2595ab7481494554db33256ed6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wide-angle photo of an Australian kangaroo mid-hop in a rocky outback with native grasses blowing in the wind\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6206360e43814351b538f906f44d205a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aerial shot raw photo of a flock of colorful parrots flying in unison over a lush, tropical rainforest canopy.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a932b7a58e54490adf050fb0ac8bcb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full shot raw photo of a golden retriever frolicking on the shoreline during sunset at a bustling beach\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba65dbb33d54467b1ae5b49371d55d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for classname in image_classes:\n",
    "\n",
    "    image_path = os.path.join(root, classname['classname'])\n",
    "    \n",
    "    # delete folder if it exists. Create empty folder in any case\n",
    "    if os.path.exists(image_path):\n",
    "        shutil.rmtree(image_path)\n",
    "    os.makedirs(image_path)\n",
    "\n",
    "    for image_idx in range(classname['samples']):\n",
    "        prompt = generate_prompt(classname['classname'])\n",
    "        print(prompt)\n",
    "\n",
    "        image = generate_images(\n",
    "            pipe= classname['pipe'],\n",
    "            prompt= prompt,\n",
    "            suffix= classname['suffix'],\n",
    "            negative_prompt= classname['negative_prompt'],\n",
    "            )[0]\n",
    "\n",
    "        image.save(os.path.join(image_path, f\"{prompt}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_class = 3\n",
    "\n",
    "for classname in image_classes:\n",
    "    print(f\"{classname['classname']}:\")\n",
    "    image_path = os.path.join(root, classname['classname'])\n",
    "    image_list = [os.path.join(image_path, image) for image in os.listdir(image_path) if image.endswith('.png')]\n",
    "\n",
    "    show_images(images=image_list[:samples_per_class], cols=3, source='local')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
